\chapter{Simulations}
In this chapter, we detail simulations that we developed to test our hypothesis, that a WSN with knowledge-processing capabilities will be able to deliver interesting data quicker than a standard WSN and increase the efficiency of the network, with a complete implementation of K-HAS and variations of this architecture that provide different levels of knowledge-processing capabilities at each tier, pushing more capabilities out towards the edge of the network; at the cost of battery life.

The simulations were developed to determine whether K-HAS is the best mix of processing and collection nodes that maximises network lifetime while minimising the transmission time of interesting data. This was done by using a fixed network structure and changing the knowledge-processing capabilities on each node at every tier; ranging from no knowlege on all node to the maximum knowledge-processing capabilities across the network.

This chapter is structured as follows. Section 2 describes the implementation of the network. Section 3 outlines the results and Section 4 compares these with LORIS and the current solution in our motivating scenario. Section 5 concludes our findings and highlights areas that require further experimentation.

\section{Simulation Environment}

Using RePast, a Java-based network simulation tool, we created a network to emulate K-HAS. Repast is an agent-based modelling system that allows for agents to be created and placed on a grid. Ticks denote a period of time and simulations can run for a fixed number of ticks, or until stopped. Ticks can also be used to schedule events, such as searching for neighbours, by calling methods that last for a set number of ticks, or begin at a particular tick. Similar to the chaining of rules we described with Drools, ticks are the core of Repast's scheduling mechanism which can be used to schedule single events, as well as chaining events. For example, a train may take three hundred for it to arrive at its destination. When the simulation reaches three hundred ticks, a scheduled event could run that would open the train doors, make an announcement and so on.

RePast was chosen because we did not require the low level network configuration provided by other tools, such as NS2, but we did need to modify and record the behaviour between nodes as they capture and process sensed data. Modelling these nodes as agents allowed for this and the flexibility of RePast allowed us to modify the configuration of the nodes during a run with ease.

Agents are created, using the RePast SDK, and Java classes are used to manipulate their behaviour. Simple networks may only contain basic agents with only a few variations from those provided by RePast. However, for more complex networks, a hierarchy of agents is required and Java's inheritance can then be used create subclasses of an agent.

A 2D space is used to display the grid and the simulation is run within Repast's own GUI. This GUI provides functionality such as editing the properties of classes, integrating with Matlab, taking screenshots and saving different configurations of the same network.

\section{Experimental Design}\label{sim:imp}
	While the aim of these simulations was to show the effectiveness of K-HAS over the current solution, we also wanted to determine if it was the optimal solution, in terms of delivery of interesting data and in terms of network lifetime. We believe that the ideal solution would be to attach nodes with high knowledge-processing capabilities to all cameras in the network, however the short battery life means that replacements would be made as often as the current manual solution. 

	Throughout this chapter, we will be referring to nodes tasked with different purposes as the three definitions listed here:
	\begin{itemize}
		\item Sensing Node: A node that has been tasked with the captuing, and routing, of sensed data.
		\item Routing Node: A node that serves a subset of sensing nodes and is tasked with collecting and aggregating sensed data.
		\item Central Node: A node with similar functionality to a typical base station, tasked with storing all sensed data and providing an interface to users.
	\end{itemize}

	The tiers are identical to K-HAS although, at the routing and sensing tier, the degree of knowledge processing capabilities can range from the levels outlined below:
	
	\begin{itemize}
		\item No Knowledge (NK): The node possesses no knowledge processing capabilities.
		\item Low Knowledge (LK): The node possesses basic knowledge processing capabilities and contains a static rule base.
		\item High Knowledge (HK): The node possesses high knowledge processing capabilities and is able to process data, metadata and use a dynamic rule base.
	\end{itemize}
	
	HK nodes, while more accurate, their battery life is much shorted than with LK nodes, due to their increased power needs. In contrast, LK nodes can run for a longer period without human interaction. LK nodes, however, are unable to classify observations to the same level as HK nodes. While HK nodes can classify an observation as interesting or empty and, in our scenario, match to a species, LK nodes can only mark an observation as interesting as they lack the capabilities to reliably determine whether an observation is empty or not. The scenarios we have implemented cover the possible combinations of HK, LK and NK, in a twenty five node network. Twenty five nodes have been used because this is the size of the network used in our motivating scenario and the number we experimented with in Danau Girang. These were developed to determine which combination of LK, NK and HK nodes allowed for the greatest network lifetime, as well as the greatest accuracy when delivering interesting sensed data, and they have been outlined below:
	
	\begin{itemize}
		\item NK-ALL: Sensing and routing nodes possess no knowledge processing capabilities.
		\item LK- ALL: Sensing and routing nodes possess low knowledge processing capabilities.
		\item NK-LK: Sensing nodes possess no knowledge processing and routing nodes have low knowledge.
		\item LK-HK (K-HAS): Sensing nodes have low knowledge and routing nodes possess high knowledge.
		\item HK-ALL: Sensing and routing nodes have high processing capabilities.
	\end{itemize}

Before implementing, we designed the agents required based largely on the existing ontology. Using that, we created a hierarchy of nodes inheriting common properties from a node object. As previously mentioned, we had metrics on range and transmission times from previous experiments and the deployment of LORIS. We used these to create properties for each transmission medium that could be used by each node object.

We also needed to create an object to represent the DwC archives, a Drools REST API had been implemented to work with the LORIS web interface, and much of the DwC archive code was reusable within RePast. 

The structure of the simulation is as follows: The \textit{network builder} instantiates all the nodes, places them randomly on the grid and schedules events once the simulation has started. The nodes then use the properties of their transmission medium to find nodes in range and create a connection; depicted by a line between the node. The simulation uses metrics extracted from the images taken at Danau Girang and the chance of an image being captured by a camera is based on the average capture rate of a camera. The fire rate has been calculated by the average number of pictures captured in a day taken by each camera. Figure \ref{fig:sim} shows an example simulation of the LK-HK scenario. The panel on the left defines the parameters set before the simulation runs, such as: the number of each node type and the size of the space, and the main panel shows the layout of the network, with nodes linked by red lines.


	\begin{figure}[h]
	\centering
	\includegraphics[width=0.70\textwidth]{Chap7/figures/khas_sim}
	\caption{LK-HK Simulation Example in RePast Simulator}
	\label{fig:sim}
	\end{figure}


%\begin{itemize}
%\item Network Builder
%\item Node
%	\begin{itemize}
%	\item Sensing
%	\item Routing
%	\item Central
%	\end{itemize}
%\item Darwin Core
%	\begin{itemize}
%	\item Identification
%	\item Location
%	\item Occurrence
%	\item Image
%	\item Species
%	\end{itemize}	 
%\end{itemize}

\subsection{Darwin Core}
The Darwin Core class represents a DwC archive, encapsulating \textit{Identification}, \textit{Location}, \textit{Occurrence}, \textit{Image} and \textit{Species}. The images we have collected from Danau Girang were processed to find details such as the average size when captured at night and day, how often an average camera triggers and the percentage of images with animal content. These data were then used to specify how often a randomly placed node should capture an observation per tick.

Upon each capture, images are created, given a random size based on the maximum and minimum size found in the 120,000 images collected from DG and the sum of the images is used to calculate the size of the archive. Using this size, a sensing node calculates how long the archive takes to send based on the size and the transmission rate. We assume that the rate stays constant for the duration of transmission.
When an archive is sent to the routing node, we used the average time for our image processing tool and Drools engine to run and attempt a classification, which is 143 seconds (ticks). To keep the classifications as general as possible, so that the simulation applies to any WSN for scientific observations, archives are not classified down to the species level, they are marked as \textit{interesting} or \textit{empty} and then forwarded to the central node.

\subsection{Routing}
The routing protocol used needs to be dynamic in order to adapt to nodes being added and removed during deployment, while minimising traffic in a resource constrained network. In our approach, we use a modification the Minimum Cost Forwarding Algorithm (MCFA), described in Section \ref{bg:rp}. A cost is assigned to each node, based on how far they are from the central node, with neighbouring nodes choosing to connect to the node with the lowest cost. However, in normal implementations of MCFA, all nodes are of the same type and simply need to connect to a base station. This protocol is used in all scenarios.

In our K-HAS architecture, sensing nodes cannot connect directly to a central node because processing would not take place. Because of this, we used the same routing method across all scenarios. Our implementation of MCFA works with a discovery phase and a transmission phase. The discovery phase is a scheduled event, taking place at the start of deployment but it can be run throughout deployment to react to nodes being added or removed. 

\subsubsection{Discovery}
	Discovery begins at each central node, scanning nodes in range for routing nodes and sending a broadcast packet, with a cost of 0, to inform them that they are within range of a central node. Links between Central and Routing nodes use W-Fi in all of our scenarios. Once received, routing nodes increment the count and forward the packet to any routing nodes within range of them, where we use the range of Zigbee. We found that this method overloaded the routing nodes and all sensing nodes within range would connect to the first routing node they receive the broadcast from. We then implemented a method, called \textit{load balancing}, which uses the sensing nodes connected to a routing node to calculate whether it should offload new nodes to a neighbouring routing node.
	
	The maximum connections a routing node can have is determined by the total number of sensing nodes in the network divided by the total number of routing nodes, which is held in the knowledge base of the central node. Once a routing node has the maximum number of connections allowed, it starts to offload to a neighbouring routing node that is also in range of the sensing node requesting a connection. If there are no neighbouring nodes then it the node exceeds the maximum number of connections allowed, to save sensing nodes being left with nowhere to send their data.
	
	If the sensing node that receives the broadcast does not have an existing route to a central node, or the cost of the current route is higher than the received route, it adds an edge to the routing node, increments the count and forwards it to all nodes in range. This process continues until the broadcast reaches the edge of the network. Nodes do not have global knowledge of the route to the central node, only of their neighbour with the lowest cost.
	
	This phase can be repeated throughout the course of the deployment, simply by scheduling it as an event to occur every \textit{n} ticks. However, the simulation currently only uses the discovery phase at the beginning of the deployment.
	
\subsubsection{Transmission}
	Once the discovery phase has been completed, providing nodes are within range of the central node, the transmission phase begins where only DwC archives are then sent across the network. Observations are captured based on the mode of the simulation and sent to the lowest cost neighbour.
	
	In order to manage transmissions, sensing nodes have a \textit{SendState} object that contains the next archive to send, the time to send it and whether it is currently sending. This is used to determine what operations to perform, once an archive has been sent, it is delete from the SendState and the sending flag is set to false. A new archive is then added and sent when the opportunity arises.
	
	When a routing node receives the archive, it begins processing. Routing nodes use the SendState as well, but they only add an archive once it has been processed and they then select the oldest archive that has been classified as interesting, providing an archive is not already waiting to be sent. The archive stores information about the route it takes, recording every hop, as well as the time it took from capture to central node.
	
	Scheduled sending events run every thousand ticks, which is configurable, to check the sending state of the node and send any archives in the SendState. The node then waits for the number of ticks that it will take in order to transmit the archive.
	
	Once the simulation is completed, either manually or through a defined number of ticks, the archives in each central node are iterated over and written to a CSV file, with details such as the path it took, total transmission time and time of capture.
	
\subsection{Capture}
	Using the existing data collected from Danau Girang, we calculated how often a camera triggers in a six month deployment, as well as how often the observation contained interesting content. 
	
	To calculate the count of interesting images, we processed every directory of images to extract the largest object in the foreground, using our Triton program. Once processed, we iterated through every directory, counted the total number of images and the total number of extracted images. This gave us a 20.7\% chance of an image being interesting, across every camera.
	
	The chance of a camera being triggered each second was calculated by the total number of observations (13,399) divided by the number of seconds in six months (15,552,000). This gives a chance of 0.000861561. A random number is generated every 1000 ticks and compared to this, if the value is less than or equal to the chance, then an observation is captured.
	
\subsection{Processing}
	The types of knowledge processing capabilities that we outlined in Section \ref{sim:imp} are used in the simulation to determine which type of processing to perform on observations. The result of processing is that an observation is marked as interesting or empty. The limitation of our image processing tool is that is only the largest region of interest is extracted, even if there are multiple objects in the image. The outcome can be any of the following:
		\begin{description}
			\item True positive (TP): A region of interest is extracted that contains the object of interest in the images.
			\item False positive (FP): A region of interest is extracted that contains nothing of interest.
			\item True negative (TN): A camera is triggered with nothing of interest in the image and no region of interest is extracted.
			\item False negative (FN): An image that is not empty is captured but no region of interest extracted.
		\end{description}
	
	Using the results of the image processing application we developed (explained in Section \ref{tech:sf:triton}) for the properties of HK processing, we found that it performed with an 82\% accuracy at detecting TP images, with a 98\% accuracy for finding TN images. Nodes with LK do not have the ability to mark an image as empty, but they can mark an image as interesting. However, the results we have from our rule base are not as extensive as the results we have for Triton, so instead we use a predefined 10\% accuracy for detecting TPs.
	

\section{Results}
In this section, we explains the results from simulating each scenario in a randomly generated network graph. 

Each scenario, outlined in Section \ref{sim:imp}, runs to simulate a 6 month deployment. Using our motivating scenario, we modelled each scenario on a fixed number of nodes: 1 central node, 4 routing nodes and 20 sensing nodes. The implementation of our architecture has been limited to using Zigbee as the transmission medium between all sensing nodes, with a Wi-Fi connection between routing nodes and a central node. Sensing nodes then send an observation when it is captured or, if it has not captured anything then it checks for a backlog every ten minutes. Sensing nodes check for new observations to process every five minutes. We ran each scenario a hundred times, with each run simulating a 6 month duration. The time to process an observation using LK has been simulated to take 5 seconds compared to the 90 seconds when a node has HK capabilities; these values have been chosen based on the average processing time we derived using existing data. 

The simulations were run in two modes: ideal transmission rate and variable transmission. Ideal used a fixed transmission rate (250kbps) for Zigbee links between all sensing nodes, with all observations being sent at the highest possible rate. Real world generates a random number for the transmission rate (between 20 and 250kbps) for each sensing node link, at the time of the network's initialisation. This models the large fluctuations in both speed and range that we observed in the Malaysian rainforest when we ran tests with Zigbee equipment. The Wi-Fi range remains constant because the distance of routing nodes from central nodes, in our motivating scenario, can be made small enough that a consistently good connection is achievable.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.70\textwidth]{Chap7/figures/ideal_int_percent}
	\caption{Percentage of Interesting Observations for All Scenarios.}
	\label{fig:res:ideal:int}
\end{figure}

Figure \ref{fig:res:ideal:int} shows the percentage of interesting observations that arrive at the central node. Due to the short transmission time, almost all observations arrive in near real-time and, as such, the split between empty and interesting remains almost constant at approximately 80:20. However, the \textit{True Positive} observations are the most important as they are the interesting observations that have been marked as such. \textit{False Positives} are interesting observations that have been wrongly marked as empty. Increasing the knowledge processing capabilities of routing nodes, shown by the difference between LK-ALL and LK-HK, increases the number of TPs, as well as reducing the number of FPs. Another important point to note is that LK-HK and HK-ALL provide the same results, despite HK-ALL solely consisting of nodes with the highest knowledge processing capabilities.  This is probably due to the fact that all observations, in LK-HK, go through an HK routing node and, thus, would receive the same level of processing as in an HK-ALL scenario.

These results support our hypothesis that LK-HK is the best scenario to choose in terms of timeliness of data delivery, quality of data delivered and network lifetime, as LK-HK has all sensing nodes with low knowledge processing capabilities, allowing them to run for several months. However, with HK-ALL, all sensing nodes run with higher capabilities and are limited to run for a maximum of three weeks before battery replacement is required.

\subsection{Duration}
The ideal transmission rate runs with the transmission rates of all nodes at their theoretical maximum, giving the highest speed for both Zigbee and Wi-Fi. Figure \ref{fig:res:ideal:dur} shows the mean duration of any observation, interesting or empty, in each scenario. With the exception of NKALL, it is clear scenarios that, where more nodes have higher knowledge processing capabilities, the mean duration is increased. NKALL could be showing a higher average duration because the lack of knowledge on any of the nodes prevents it from prioritising observations, which means that some could be queued for longer before being sent on. One of the key points to note is that the difference in transmission time from capture to central node is typically no more than one hundred seconds. When compared with a standard, power efficient WSN with no knowledge processing capabilities, the reduced battery life may not be worth the trade off. However, these times are not solely for transmission, they also include in-network processing and prioritisation when they arrive at the central node. 

	\begin{figure}[h]
	\centering
	\includegraphics[width=0.70\textwidth]{Chap7/figures/ideal_all_dur}
	\caption{Mean Duration for All Observations with Ideal Transmission Rates.}
	\label{fig:res:ideal:dur}
	\end{figure}
	
	\begin{figure}[h]
	\centering
	\includegraphics[width=0.70\textwidth]{Chap7/figures/real_all_dur}
	\caption{Mean Duration of All Observations under Variable Transmission Rate.}
	\label{fig:real:dur}
	\end{figure}	

During our visits to Danau Girang, we performed experiments for many different transmission methods: Wi-Fi, Zigbee and RF. The results were always different to what we experienced in the UK and the variation in connectivity in just a few minutes, or metres, was astounding. Days where the humidity was one percent higher than the previous day could result in a 50\% range drop and rain for a few minutes could drop all connections for an hour afterwards. Modelling this in our simulations was necessary to accurately plan for what we could expect in Malaysia. Our planned network topology in Danau Girang has routing and central nodes so close to each other that the Wi-Fi connection remained fairly stable and connectivity should remain at 100\%. When simulating sensing nodes, we randomly set their transmission rate between 20 and 250kbps at the start of each run. As each scenario is being run 100 times, this method is more efficient while still allowing for variation in the transmission rates. 

The number of interesting observations received in each scenario remained the same as in the ideal mode, as expected, but the fluctuation in transmission time (Figure \ref{fig:real:dur} is much larger, with some images taking 800 seconds, or 13 minutes. In our motivating scenario, this is not much of an issue. However, if the image was of a hunter or the scenario was building intrusion detection system, then thirteen minutes is a long delay that could cause considerable damage. Of course, using all Wi-Fi connections is a more feasible option, but situations where long range is required prevents this and these simulations do not currently take into account broken links in the network, where changes to the node's environment (such as a fallen tree) or an increase in humidity, could cause it to drop out of range for minutes or even hours. 

The duration of an observation with both a variable and ideal transmission rate does not fluctuate largely and Figure \ref{fig:res:ideal:int} shows that the processing power of LK-HK vs. HK-ALL is identical. However, Figures \ref{fig:real:int:dur} and \ref{fig:real:empty:dur} show that the primary benefit of pushing HK processing capabilities out to the edge of the network allows for better prioritisation of observations. Sensing nodes with HK are able to determine whether a node is interesting or empty with much greate accuracy and these capabilities, right at the edge of the network, allows for an interesting observation to be processed as soon as it is captured and sent without further processing directly to a central node. The only delays being the processing time itself and the sending queue of intermediate nodes. Figures \ref{fig:real:int:dur} and \ref{fig:real:empty:dur}, when compared with \ref{fig:real:dur}, highlight the transmission time difference between an interesting and an empty observation, with interesting observations arriving, on average, 120 seconds before empty observations. While these numbers may only be useful in time critical scenarios, WSNs with much worse transmission rates could experience a much larger time difference between interesting observations, especially when using long range FM frequencies that can transfer only a few bytes a second.

    \begin{figure}[h]
	\centering
	\includegraphics[width=0.70\textwidth]{Chap7/figures/real_int_dur}
	\caption{Mean Duration of Interesting Observations under Variable Transmission Rate.}
	\label{fig:real:int:dur}
	\end{figure}	

	\begin{figure}[h]
	\centering
	\includegraphics[width=0.70\textwidth]{Chap7/figures/real_empty_dur}
	\caption{Mean Duration of Empty Observations under Variable Transmission Rate.}
	\label{fig:real:empty:dur}
	\end{figure}	

\subsection{Observation Saturation}

With the transmission rates of Zigbee and Wi-Fi, an observation of three images, each under a megabyte in size, can be processed and sent in a matter of minutes; when there are only a few hops. However, with these network topologies, we are unable to see how each scenario handles prioritisation when it is unable to send every observation captured. This can be done by either reducing the transmission rate or increasing the chance of an observation being captured. We chose to increase the chance of an observation being captured and maintaining the transmission rate in order to keep the simulations in line with our motivating scenario. Existing data from Danau Girang has shown a seasonality change in the number of images captured and we know that some sites are more active than others, therefore making a higher chance of capture more fitting. 

Imagine a scenario where flash floods in the rainforest prevent access to the nodes to change the battery and a mating season of sun bear has caused the capture rate to increase. The chance of an image capture has increased and users of the network have programmed the sensing nodes to increase their sleep duration to a minute; saturating the network with more images than can be sent in a six month period.

We simulated this across all five scenarios and the results are detailed in this section. The duration is increased for all observations and there is an increase in the time it takes an interesting observations when compared to an empty observation. This is because so many more are being captured however, when you look at the number delivered, we can see that the number of interesting observations delivered is much greater. This means that the network is successfully prioritising observations it believes to be interesting and not sending those that are empty because of the time and bandwidth constraints.



% \subsection{Scenarios}

% This section details the results from each scenario of increasingly capable knowledge processing nodes. NK-ALL represents a 'standard' WSN where no nodes have knowledge processing capabilities and forward to a single endpoint. NK-LK simulates a network where sensing nodes have no knowledge processing capabilities, but routing nodes have LK, allowing them to detect whether an observation is interesting, but lack the knowledge to determine, with any confidence, whether an observation is of no interest. LK-ALL simulates a network where both sensing and routing nodes have LK capabilities. LK-HK is the Repast implementation of our K-HAS architecture; sensing nodes have LK and routing nodes have HK. HK-ALL has sensing and routing nodes that have HK capabilities. 

% Table \ref{tab:observ_int} shows the time for average transmission time, in hours, for interesting observations. Interesting observations consist of \textit{true positives} and \textit{false negatives}, which means that the spread of transmission times would be quite varied, because TPs would be prioritised but FPs would be treated as empty images. However, we can see that the total of interesting images almost doubles when all nodes have HK. More importantly, the difference between HK-ALL and LK-HK is less than 2\%, while still providing a battery advantage. With LK-HK and HK-ALL, the median is much lower when compared to LK-ALL and NK-LK, due to the higher levels of knowledge processing capabilities.

% With the results broken down further, Table \ref{tab:observ_tp} shows the average duration for true positives and we can see that, while the median stays much the same for each scenario, average duration varies considerably. The average time for a TP to be sent is lower for LK-HK than for LK-ALL, this could be due to the extra processing time for HK nodes or a processing backlog with a large number of observations. Although the duration of LK-HK is approximately twice that of LK-ALL, it does deliver more TPs, with 36.46\% of all images received being TP, compared with 8.45\% for LK-ALL.

% \begin{table}[h]\footnotesize
% \begin{tabularx}{\textwidth}{ |X|X|X|X|X|}
% \hline
% Scenario & Median & Mean & Standard Deviation & \% Total\\
% \hline
% NKLK & 608 & 841.95 & 854.18 & 22.11\\
% LKALL & 127 & 652.33 & 868.09 & 24.35\\
% LKHK & 3 & 255.49 & 591.63 & 38.86\\
% HKALL & 2 & 59.57 & 320.48 & 40.78\\
% \hline
% \end{tabularx}
% \caption{Transmission Time for Interesting Observations}\label{tab:observ_int}
% \end{table}

% \begin{table}[h]\footnotesize
% \begin{tabularx}{\textwidth}{ |X|X|X|X|X|}
% \hline
% Scenario & Median & Mean & Standard Deviation & \% Total\\
% \hline
% NK-LK & 3 & 277.01 & 543.22 & 3.88\\
% LK-ALL & 2 & 99.73 & 353.16 & 8.45\\
% LK-HK & 3 & 207.09 & 518.11 & 36.46\\
% HK-ALL & 2 & 2.77 & 2.75 & 38.16\\
% \hline
% \end{tabularx}
% \caption{Transmission Time for True Positive Observations}\label{tab:observ_tp}
% \end{table}

% \begin{table}[h]\footnotesize
% \begin{tabularx}{\textwidth}{ |X|X|X|X|X|}
% \hline
% Scenario & Median & Mean & Standard Deviation & \% Total\\
% \hline
% LK-ALL & 675.5 & 945.94 & 916.11 & 15.9\\ 
% LK-HK & 683 & 989.02 & 1006.4 & 2.41\\
% HK-ALL & 553 & 885.65 & 931.19 & 2.6\\
% \hline
% \end{tabularx}
% \caption{Transmission Time for False Negative Observations}\label{tab:observ_fn}
% \end{table}

% \begin{figure}[!h]
% \centering
% \includegraphics[width=\textwidth]{Chap7/figures/all_int.png}
% \caption{Mean Transmission Time for Interesting Observations in All Scenarios}
% \label{fig:all_int}
% \end{figure}

% \begin{figure}[!h]
% \centering
% \includegraphics[width=\textwidth]{Chap7/figures/all_int_percent.png}
% \caption{Percentage of Interesting Observations in All Scenarios}
% \label{fig:all_int_percent}
% \end{figure}

% Figure \ref{fig:all_int} shows the average transmission time for interesting observations across every scenario. NK-ALL has no points for TP and FN because of its lack of processing capabilities. The drop in transmission time for interesting images is clearly visible here, but there is an increase in TN transmission time when comparing LK-ALL and LK-HK. This spike is better explained with the use of Figure \ref{fig:all_int_percent}, showing that, although it takes longer for TP images to be delivered in LK-HK, the percentage of TP images increased in LK-HK by almost four times that of LK-ALL. The faster transmission times in HK-ALL can be explained by the fact that all nodes can accurately detect empty images from the edge of the network and also prioritise interesting images with a greater accuracy than any other scenario. However, nodes with HK processing power have much higher power requirements and require battery changes every 3 weeks, this power trade off shows that nodes of this type can deliver interesting observations significantly faster than nodes with LK. A number of WSNs will place nodes in places that are not easily accessible by humans and not expected to be visited so regularly. In our motivating scenario, some nodes could be rendered inaccessible by river floods for weeks at a time and regular human traffic can prevent animals from using those sites. The percentage of TPs delivered by LK-HK and HK-ALL are not that different, but the delivery time when using both HK and LK nodes does affect the delivery time. 

% \subsection{LK-HK Scenarios}

% The main difference between HK-ALL and LK-HK is that all sensing nodes in HK-ALL have the ability to perform more intense data processing and determine which observations to prioritise with greater accuracy. Whereas LK-HK focusses on HK capabilities for the routing nodes and maximising the lifetime of sensing nodes by limiting them to LK capabilities. Therefore, we tested different proportions of LK and HK sensing nodes within the LK-HK scenario in order to determine the best ratio between performance and network lifetime. Table \ref{tab:khas_int} shows the average duration for an interesting observation when 4, 8, 12, 16 and 20 of the 20 sensing nodes have HK, with the rest having LK processing capabilities. Figure \ref{fig:khas_int_percent} illustrates how pushing knowledge further towards the edge of the network increases the delivery time and the percentage of interesting images. LK-HK 16 and LK-HK 20 have an average difference of three hours for interesting images, but LK-H K20 means that all nodes in the network have HK processing capabilities and, thus, a shorter battery life. While the difference in transmission time is not that significant, the extra LK nodes with a longer battery life means that they can be placed in areas that may not be easily accessible or need to remain undisturbed.

% \begin{table}[h]\footnotesize
% \begin{tabularx}{\textwidth}{ |X|X|X|X|}
% \hline
% Scenario & Median & Mean & Standard Deviation \\
% \hline
% LK-HK 4 & 2 & 153.21 & 462.75 \\
% LK-HK 8 & 2 & 146.04 & 428.79 \\
% LK-HK 12 & 2 & 156.95 & 461.67 \\
% LK-HK16 & 2 & 88.86 & 349.68 \\
% LK-HK 20 & 2 & 63.13 & 330.67 \\
% \hline
% \end{tabularx}
% \caption{Transmission Time Results for Interesting Observations}\label{tab:khas_int}
% \end{table}

% \begin{table}[h]\footnotesize
% \begin{tabularx}{\textwidth}{ |X|X|X|X|}
% \hline
% Scenario & Median & Mean & Standard Deviation \\
% \hline
% LK-HK 4 & 2 & 104.74 & 393.06 \\
% LK-HK 8 & 2 & 94.56 & 357.04 \\
% LK-HK 12 & 2 & 86.85 & 343.69 \\
% LK-HK16 & 2 & 29.15 & 191.82 \\
% LK-HK 20 & 2 & 2.08 & 1.93 \\
% \hline
% \end{tabularx}
% \caption{Transmission Time Results for True Positive Observations}\label{tab:khas_tp}
% \end{table}

% \begin{figure}[!h]
% \centering
% \includegraphics[width=\textwidth]{Chap7/figures/khas_int_percent.png}
% \caption{Percentage of Interesting Observations in LK-HK Variations}
% \label{fig:khas_int_percent}
% \end{figure}

% \begin{figure}[!h]
% \centering
% \includegraphics[width=\textwidth]{Chap7/figures/all_total.png}
% \caption{Mean Duration for All Observations in Zigbee Scenarios}
% \label{fig:all_total}
% \end{figure}

% \subsection{Unrestricted Transmission Speeds}
% In this section, we manipulated the variables set in out original simulations, that were based on existing sensed data, to identify bottlenecks that prevented observations from being received immediately. Zigbee has a low transmission rate, of 2.77 Kbps, therefore we expected increasing the transmission rate of all nodes in the network to a rate in the thousands (61920 Kbps) to determine whether this would reduce the mean transmission time for all images. Figure \ref{fig:unres_int} shows that, when compared with Figure \ref{fig:all_int}, the transmission time is reduced in all scenarios, by up to half in some cases. HK-ALL shows that this increase allows for interesting observations to be delivered with almost no delay, in near real-time. However, with a rate that should allow almost all observations to be sent in a matter of seconds, many scenarios still have a delay of 600 hours. Figure \ref{fig:unres_total} shows the average duration for all observations received at the central node and, with Wi-Fi transmission rates, we expected this to be much higher. However, when compared with Figure \ref{fig:all_total}, which shows the average duration for all observations using Zigbee as the transmission medium, we can see that the transmission time for most scenarios reduces to fewer than 500 hours. HK-ALL, remains much the same, despite the faster transmission rate. 

% Another bottleneck that we identified was the duration that each node would check for new observations, and process them. In the current solution, sensing nodes check every 10 minutes and routing nodes check every 5. This delay could cause an observation to not be picked up immediately, as well as the transmission delay. To test this, we reduced the Sensing node check to every minute and the Routing node to check every 30 seconds for new observations. Using Zigbee, the mean transmission time for all observations, in the HK-ALL scenario, was 501.02 hours. Using the increased transmission rate, it was 354.34 hours and with the reduced checking delay, the time dropped to 1.58 hours. Therefore, in order to create a real time implementation of these scenarios, one would need to use a fast transmission medium, such as Wi-Fi, and increase the time delay to check for new data; both of which would reduce the battery life of the node. This solution would ensure that all sensed data would be received almost as soon as it was captured, however, our HK-ALL Zigbee implementation would deliver interesting images within 3 hours but conserve battery life by using a radio with less power consumption and checking for new data less often. This faster solution would be primarily suited to deployments where power is not a constraint, but the real-time receipt of all sensed data is.

% \begin{figure}[!h]
% \centering
% \includegraphics[width=\textwidth]{Chap7/figures/unres_all_int.png}
% \caption{Mean Duration for Interesting Observations in Unrestricted Scenarios}
% \label{fig:unres_int}
% \end{figure}

% \begin{figure}[!h]
% \centering
% \includegraphics[width=\textwidth]{Chap7/figures/unres_all_total.png}
% \caption{Mean Duration for All Observations in Unrestricted Scenarios}
% \label{fig:unres_total}
% \end{figure}

\section{Conclusion}
	
In this chapter, we have detailed the development of simulations to show the different scenarios for pushing knowledge further out into a network. Using different levels of knowledge processing capabilities on nodes, we have shown that a network with HK processing capabilities can detect and prioritise interesting images, while simultaneously delaying empty images for a time when the network is not busy. However, using a network that solely comprises of HK nodes results in a battery life that lasts for 3 weeks on each node. The K-HAS network architecture we have proposed provides a combination of HK and LK nodes, distributed based on their role in the network, for example, nodes tasked with sensing and forwarding images only have LK processing capabilities. These simulations have shown that the HK-LK scenario results in a delay of interesting image delivery, when compared to LK-ALL, but the percentage of interesting images delivered is significantly increased.

Using a real world mode, we have seen that the variation in transmission times can be quite large, but the difference between LK-HK and HK-ALL is not that great. This proves that our K-HAS solution  is the best solution for most scenarios as it provides a longer network lifetime with same ratio of TP:FN images as a network where every node is equipped with HK.

While the simulation is not feature complete, we believe it is accurate enough to show how LK-HK utilises the knowledge-processing capabilities at each tier to process, and prioritise, sensed data based on knowledge gained from the environment, previously sensed data and from humans using the network. Our results also show that the difference between LK-HK and HK-ALL is  not significant enough to warrant the loss in network lifetime. However, not every scenario would be suited to this. NK-LK shows a slightly faster transmission time and a much longer network lifetime, as most nodes would not have any processing power. While the processing of sensed data would not be enough to rely on, it could act as pre-processing that could be processed further once power is not an issue. This would be well suited for networks where nodes have limited power and are not easily accessible, such as bird nest monitoring networks. 

LK-HK allows sensed data to be processed, and delivered, in near real-time with approximately 87\% of all interesting data being correctly classified. This number could increase the longer that the network is deployed and this is something we would like to investigate in the future.







































